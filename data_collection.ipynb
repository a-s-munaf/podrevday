{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All Tweets with #podrevday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!GetOldTweets3 --querysearch \"podrevday\" --since 2020-01-01 --until 2020-07-10 --output \"data/jan-july-2020.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import geonamescache\n",
    "from geotext import GeoText\n",
    "\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "import twint\n",
    "\n",
    "df = pd.read_csv('data/jan-july-2020.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_rev_users = list(set(df.username))\n",
    "\n",
    "c = twint.Config()\n",
    "c.Store_object = True\n",
    "c.Pandas = True\n",
    "\n",
    "for user in pod_rev_users: \n",
    "    c.Username = user\n",
    "    twint.run.Lookup(c)\n",
    "Users_df = twint.storage.panda.User_df\n",
    "\n",
    "users_df = Users_df.drop_duplicates()\n",
    "users_df.to_csv('data/user_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'avatar', 'background_image', 'bio', 'followers',\n",
       "       'following', 'id', 'join_date', 'join_datetime', 'join_time', 'likes',\n",
       "       'location', 'media', 'name', 'private', 'tweets', 'url', 'username',\n",
       "       'verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = pd.read_csv('data/user_data.csv')\n",
    "user_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = user_df.loc[:, ['id','username', 'name', 'location', 'join_date', 'followers', 'following', 'likes', 'url', 'verified' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>join_date</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>likes</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>967456758812753921</td>\n",
       "      <td>PiecingPod</td>\n",
       "      <td>Piecing It Together Podcast ðŸ§©</td>\n",
       "      <td>blank</td>\n",
       "      <td>24 Feb 2018</td>\n",
       "      <td>1460</td>\n",
       "      <td>1153</td>\n",
       "      <td>15263</td>\n",
       "      <td>https://www.piecingpod.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454586852</td>\n",
       "      <td>thetwoohsix</td>\n",
       "      <td>The Marcdalorian</td>\n",
       "      <td>Seattle, WA aka The TwoOhSix</td>\n",
       "      <td>3 Jan 2012</td>\n",
       "      <td>1033</td>\n",
       "      <td>1712</td>\n",
       "      <td>17341</td>\n",
       "      <td>http://anchor.fm/thetwoohsix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4762526247</td>\n",
       "      <td>80dayspodcast</td>\n",
       "      <td>80 Days Podcast</td>\n",
       "      <td>Global</td>\n",
       "      <td>10 Jan 2016</td>\n",
       "      <td>365</td>\n",
       "      <td>383</td>\n",
       "      <td>256</td>\n",
       "      <td>https://80dayspodcast.com/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1154876846749523968</td>\n",
       "      <td>PodNationPods</td>\n",
       "      <td>PodNation</td>\n",
       "      <td>blank</td>\n",
       "      <td>26 Jul 2019</td>\n",
       "      <td>4491</td>\n",
       "      <td>3107</td>\n",
       "      <td>20149</td>\n",
       "      <td>https://www.podchaser.com/lists/PodNation-107Z...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1213556989776629761</td>\n",
       "      <td>summer_skills</td>\n",
       "      <td>Summer | Skill Investor</td>\n",
       "      <td>Location Independent</td>\n",
       "      <td>4 Jan 2020</td>\n",
       "      <td>52</td>\n",
       "      <td>160</td>\n",
       "      <td>831</td>\n",
       "      <td>http://linktr.ee/summeraims</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id       username                           name  \\\n",
       "0   967456758812753921     PiecingPod  Piecing It Together Podcast ðŸ§©   \n",
       "1            454586852    thetwoohsix               The Marcdalorian   \n",
       "2           4762526247  80dayspodcast                80 Days Podcast   \n",
       "3  1154876846749523968  PodNationPods                      PodNation   \n",
       "4  1213556989776629761  summer_skills        Summer | Skill Investor   \n",
       "\n",
       "                       location    join_date  followers  following  likes  \\\n",
       "0                         blank  24 Feb 2018       1460       1153  15263   \n",
       "1  Seattle, WA aka The TwoOhSix   3 Jan 2012       1033       1712  17341   \n",
       "2                        Global  10 Jan 2016        365        383    256   \n",
       "3                         blank  26 Jul 2019       4491       3107  20149   \n",
       "4          Location Independent   4 Jan 2020         52        160    831   \n",
       "\n",
       "                                                 url  verified  \n",
       "0                         https://www.piecingpod.com         0  \n",
       "1                       http://anchor.fm/thetwoohsix         0  \n",
       "2                         https://80dayspodcast.com/         0  \n",
       "3  https://www.podchaser.com/lists/PodNation-107Z...         0  \n",
       "4                        http://linktr.ee/summeraims         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.loc[:, \"location\"] = user_df.loc[:, \"location\"].fillna(\"blank\")\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.loc[:, \"geotext\"] = user_df.loc[:, \"location\"].apply(GeoText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.loc[:, 'city'] = user_df.loc[:, 'geotext'].apply(lambda x: x.cities)\n",
    "user_df.loc[:, 'country'] = user_df.loc[:, 'geotext'].apply(lambda x: x.countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geonamescache import GeonamesCache\n",
    "gc = GeonamesCache()\n",
    "countries = gc.get_countries()\n",
    "country_info = pd.DataFrame(countries).T\n",
    "country_info = country_info.set_index('geonameid').reset_index()\n",
    "name_code = country_info.loc[:, [\"name\", \"iso3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "             \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\",\n",
    "             \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\",\n",
    "             \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\",\n",
    "             \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"USA\", \"United States\",\n",
    "             'Seattle', \"Los Angeles\", \"Houston\", \"Atlanta\", \"Pittsburgh\"]\n",
    "\n",
    "us_state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \n",
    "               \"District \", \"of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \n",
    "               \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \n",
    "               \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \n",
    "               \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \n",
    "               \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \n",
    "               \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n",
    "\n",
    "can_prov_abbrev = {'Alberta': 'AB','British Columbia': 'BC','Manitoba': 'MB', 'New Brunswick': 'NB',\n",
    "                       'Newfoundland and Labrador': 'NL', 'Northwest Territories': 'NT','Nova Scotia': 'NS','Nunavut': 'NU',\n",
    "                       'Ontario': 'ON','Prince Edward Island': 'PE', 'Quebec': 'QC','Saskatchewan': 'SK','Yukon': 'YT'}\n",
    "\n",
    "can_prov_names, can_prov_abbr = zip(*can_prov_abbrev.items())\n",
    "\n",
    "uk = [\"England\", 'Wales', \"Scotland\", 'London', \"Manchester\", \"Isle of Wight\", \"Northern Ireland\", \"United Kingdom\", 'Bailiwick of Guernsey', \"UK\", \"Hoxton\", \"Jersey\"]\n",
    "\n",
    "india_city = [\"Bangalore\", \"Delhi\", \"Hyderabad\", \"Bengaluru\"]\n",
    "\n",
    "german_city = [\"Munich\", \"Berlin\", \"eisgau\",\"Hamburg\", \"Dortmund\"]\n",
    "\n",
    "south_africa = [\"South Africa\", \"Durban\", \"Johannesburg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(area, name):\n",
    "    user_df.loc[(user_df.location.str.contains('|'.join(area))), \"country\"] = name    \n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = replacer(can_prov_names, \"Canada\")\n",
    "user_df = replacer(can_prov_abbrev, \"Canada\")\n",
    "user_df = replacer(us_state_names, \"United States\")\n",
    "user_df = replacer(us_states, \"United States\")\n",
    "user_df = replacer(uk, \"United Kingdom\")\n",
    "user_df = replacer(german_city, \"Germany\")\n",
    "user_df = replacer(south_africa, \"South Africa\")\n",
    "user_df = replacer(india_city, \"India\")\n",
    "user_df.loc[(user_df.location == \"Italia\"), \"country\"] = \"Italy\" \n",
    "user_df.loc[(user_df.location == \"Belgrade\"), \"country\"] = \"Serbia\" \n",
    "user_df.loc[(user_df.country == \"PolandSerbia\"), \"country\"] = \"Poland\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df[\"city\"] = user_df['city'].apply(lambda x: \"\".join(map(str, x)))\n",
    "user_df[\"country\"] = user_df['country'].apply(lambda x: \"\".join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_2 = pd.merge(left=user_df,\n",
    "                    right=name_code,\n",
    "                    how='left',\n",
    "                    left_on='country',\n",
    "                    right_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_2.drop('name_y',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge User's Geographic Data with Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(left=df, \n",
    "                   right=user_df_2, \n",
    "                   how='left',\n",
    "                   on='username')\n",
    "\n",
    "full_df.to_csv('data/tweets_users.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
